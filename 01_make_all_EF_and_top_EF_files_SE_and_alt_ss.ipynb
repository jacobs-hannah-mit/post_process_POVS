{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a79ca54-d51e-4133-b64f-8411f32e96d3",
   "metadata": {},
   "source": [
    "Script: to concat files and assign top EF\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a7860c-b7bd-4f1d-a157-d02d2cd2a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c63f36-ffd3-4e9a-b83f-b87dd49ebab9",
   "metadata": {},
   "source": [
    "Function to filter our background exons\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c6d0f-4c6e-4d59-902a-931837164ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bc33e54-29b8-45e4-a09f-9145cc62241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_save_exons(type_ss):\n",
    "    all_EFs_df=pd.DataFrame()\n",
    "    directory_path = '/Users/hannahjacobs/Dropbox (MIT)/GradSchool/Finucane/splicing_variation_in_humans_2022/data/00_data/emp_bayes_output/'+type_ss+'_outputs/assigned_EFs/'\n",
    "    files=os.listdir(directory_path)\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for file_name in files:\n",
    "        # Check if the entry is a file (not a directory)\n",
    "        if file_name!= '.ipynb_checkpoints':\n",
    "    \n",
    "            df = pd.read_csv(directory_path+file_name)\n",
    "    \n",
    "            df['tissue']=file_name.split('_EFs')[0]\n",
    "    \n",
    "            all_EFs_df=pd.concat([all_EFs_df, df])\n",
    "            # Add your code here to do something with the file\n",
    "    \n",
    "    #check for convergence\n",
    "    all_EFs_df = all_EFs_df[all_EFs_df['function_output_emp_bayes'].apply(lambda x: x.split('success: ')[1].split('\\n')[0])=='True']\n",
    "    \n",
    "    #filter background\n",
    "    all_EFs_background_SE = all_EFs_df[~all_EFs_df.passed_min_threshold_in_tissue]\n",
    "    \n",
    "    all_EFs_above_5_percent_PSI = all_EFs_df[all_EFs_df.passed_min_threshold_in_tissue]\n",
    "    \n",
    "    EF_5_bin = pd.cut(all_EFs_above_5_percent_PSI.EF_5, [0,0.1,0.3,0.5,0.7,0.9,1.0])\n",
    "    \n",
    "    all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(EF_5_bin=EF_5_bin)\n",
    "    \n",
    "\n",
    "    if type_ss=='alt_ss':\n",
    "        intron_1=all_EFs_above_5_percent_PSI.intron_1.apply(lambda x: x.split(':clu')[0])\n",
    "\n",
    "        intron_2=all_EFs_above_5_percent_PSI.intron_2.apply(lambda x: x.split(':clu')[0])\n",
    "        \n",
    "        cluster_name_no_ID=intron_1+'_'+intron_2\n",
    "        \n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(cluster_name_no_ID=cluster_name_no_ID)\n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(splicing_event='alt_splice_site')\n",
    "        \n",
    "        \n",
    "\n",
    "    elif type_ss=='se':\n",
    "\n",
    "            \n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(intron_1_unskipped=all_EFs_above_5_percent_PSI.cluster_name.apply(lambda x:  x.split('_chr')[0]))\n",
    "    ########\n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(intron_2_unskipped=all_EFs_above_5_percent_PSI.cluster_name.apply(lambda x: 'chr'+x.split('_chr')[2]+':'+x.split(':')[3].split('_chr')[0]))\n",
    "                                                                                                                                  \n",
    "    \n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(intron_skipped=all_EFs_above_5_percent_PSI.cluster_name.apply(lambda x: 'chr'+x.split('_chr')[1]))\n",
    "    \n",
    "\n",
    "        exclusion=all_EFs_above_5_percent_PSI[all_EFs_above_5_percent_PSI.minority_is_exclusion_event]\n",
    "        \n",
    "        # For 'exclusion' DataFrame\n",
    "        intron_1_exclusion = exclusion.cluster_name.apply(lambda x: x.split('_chr')[0])\n",
    "        exclusion = exclusion.assign(intron_1=intron_1_exclusion)\n",
    "        \n",
    "        intron_2_exclusion = exclusion.cluster_name.apply(lambda x: 'chr'+x.split('_chr')[1])\n",
    "\n",
    "\n",
    "        exclusion = exclusion.assign(intron_2=intron_2_exclusion)\n",
    "        \n",
    "        # For 'inclusion' DataFrame\n",
    "        inclusion=all_EFs_above_5_percent_PSI[~all_EFs_above_5_percent_PSI.minority_is_exclusion_event]\n",
    "        \n",
    "        intron_1_inclusion = inclusion.cluster_name.apply(lambda x: x.split('_chr')[0])\n",
    "        inclusion = inclusion.assign(intron_1=intron_1_inclusion)\n",
    "\n",
    "\n",
    "        \n",
    "        intron_2_inclusion = inclusion.cluster_name.apply(lambda x: 'chr'+x.split('_chr')[1])\n",
    "        inclusion = inclusion.assign(intron_2=intron_2_inclusion)\n",
    "        \n",
    "        # Combining 'inclusion' and 'exclusion' DataFrames\n",
    "        all_EFs_above_5_percent_PSI = pd.concat([inclusion, exclusion])\n",
    "        \n",
    "                \n",
    "        all_EFs_above_5_percent_PSI=pd.concat([inclusion, exclusion])\n",
    "\n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(splicing_event='skipped_exon')\n",
    "         \n",
    "    top_EF_all_tissues = all_EFs_above_5_percent_PSI.sort_values(by='EF_5', ascending=False).drop_duplicates(subset='cluster_name_no_ID', keep='first')\n",
    "    \n",
    "\n",
    "    return all_EFs_above_5_percent_PSI, top_EF_all_tissues\n",
    "\n",
    "        \n",
    "   \n",
    "        \n",
    "                            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5dc08a4e-9830-42b4-b920-fcdcbd457b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_and_save_exons_new(type_ss):\n",
    "    all_EFs_df=pd.DataFrame()\n",
    "    directory_path = '/Users/hannahjacobs/Dropbox (MIT)/GradSchool/Finucane/splicing_variation_in_humans_2022/data/00_data/emp_bayes_output/'+type_ss+'_outputs/assigned_EFs/'\n",
    "    files=os.listdir(directory_path)\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for file_name in files:\n",
    "        # Check if the entry is a file (not a directory)\n",
    "        if file_name!= '.ipynb_checkpoints':\n",
    "    \n",
    "            df = pd.read_csv(directory_path+file_name)\n",
    "    \n",
    "            df['tissue']=file_name.split('_EFs')[0]\n",
    "    \n",
    "            all_EFs_df=pd.concat([all_EFs_df, df])\n",
    "            # Add your code here to do something with the file\n",
    "    \n",
    "    #check for convergence\n",
    "    all_EFs_df = all_EFs_df[all_EFs_df['function_output_emp_bayes'].apply(lambda x: x.split('success: ')[1].split('\\n')[0])=='True']\n",
    "    \n",
    "    #filter background\n",
    "    all_EFs_background_SE = all_EFs_df[~all_EFs_df.passed_min_threshold_in_tissue]\n",
    "    \n",
    "    all_EFs_above_5_percent_PSI = all_EFs_df[all_EFs_df.passed_min_threshold_in_tissue]\n",
    "    \n",
    "    EF_5_bin = pd.cut(all_EFs_above_5_percent_PSI.EF_5, [0,0.1,0.3,0.5,0.7,0.9,1.0])\n",
    "    \n",
    "    all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(EF_5_bin=EF_5_bin)\n",
    "    \n",
    "\n",
    "    if type_ss=='alt_ss':\n",
    "        intron_1=all_EFs_above_5_percent_PSI.intron_1.apply(lambda x: x.split(':clu')[0])\n",
    "\n",
    "        intron_2=all_EFs_above_5_percent_PSI.intron_2.apply(lambda x: x.split(':clu')[0])\n",
    "        \n",
    "        cluster_name_no_ID=intron_1+'_'+intron_2\n",
    "        \n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(cluster_name_no_ID=cluster_name_no_ID)\n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(splicing_event='alt_splice_site')\n",
    "        \n",
    "        \n",
    "\n",
    "    elif type_ss=='se':\n",
    "\n",
    "            \n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(intron_1_unskipped=all_EFs_above_5_percent_PSI.cluster_name.apply(lambda x:  x.split('_chr')[0]))\n",
    "    ########\n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(intron_2_unskipped=all_EFs_above_5_percent_PSI.cluster_name.apply(lambda x: 'chr'+x.split('_chr')[2]+':'+x.split(':')[3].split('_chr')[0]))\n",
    "                                                                                                                                  \n",
    "    \n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(intron_skipped=all_EFs_above_5_percent_PSI.cluster_name.apply(lambda x: 'chr'+x.split('_chr')[1]))\n",
    "    \n",
    "\n",
    "        exclusion=all_EFs_above_5_percent_PSI[all_EFs_above_5_percent_PSI.minority_is_exclusion_event]\n",
    "        \n",
    "        # For 'exclusion' DataFrame\n",
    "        intron_1_exclusion = exclusion.cluster_name.apply(lambda x: x.split('_chr')[0])\n",
    "        exclusion = exclusion.assign(intron_1=intron_1_exclusion)\n",
    "        \n",
    "        intron_2_exclusion = exclusion.cluster_name.apply(lambda x: 'chr'+x.split('_chr')[1])\n",
    "\n",
    "\n",
    "        exclusion = exclusion.assign(intron_2=intron_2_exclusion)\n",
    "        \n",
    "        # For 'inclusion' DataFrame\n",
    "        inclusion=all_EFs_above_5_percent_PSI[~all_EFs_above_5_percent_PSI.minority_is_exclusion_event]\n",
    "        \n",
    "        intron_1_inclusion = inclusion.cluster_name.apply(lambda x: x.split('_chr')[0])\n",
    "        inclusion = inclusion.assign(intron_1=intron_1_inclusion)\n",
    "\n",
    "\n",
    "        \n",
    "        intron_2_inclusion = inclusion.cluster_name.apply(lambda x: 'chr'+x.split('_chr')[1])\n",
    "        inclusion = inclusion.assign(intron_2=intron_2_inclusion)\n",
    "        \n",
    "        # Combining 'inclusion' and 'exclusion' DataFrames\n",
    "        all_EFs_above_5_percent_PSI = pd.concat([inclusion, exclusion])\n",
    "        \n",
    "                \n",
    "        all_EFs_above_5_percent_PSI=pd.concat([inclusion, exclusion])\n",
    "\n",
    "        intron_1=all_EFs_above_5_percent_PSI.intron_1.apply(lambda x: x.split(':clu')[0])\n",
    "\n",
    "        intron_2=all_EFs_above_5_percent_PSI.intron_2.apply(lambda x: x.split(':clu')[0])\n",
    "        \n",
    "        cluster_name_no_ID=intron_1+'_'+intron_2\n",
    "\n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(splicing_event='skipped_exon')\n",
    "\n",
    "        all_EFs_above_5_percent_PSI=all_EFs_above_5_percent_PSI.assign(cluster_name_no_ID=cluster_name_no_ID)\n",
    "\n",
    "        \n",
    "         \n",
    "    top_EF_all_tissues = all_EFs_above_5_percent_PSI.sort_values(by='EF_5', ascending=False).drop_duplicates(subset='cluster_name_no_ID', keep='first')\n",
    "    \n",
    "    all_EFs_above_5_percent_PSI.to_csv('/Users/hannahjacobs/Dropbox (MIT)/GradSchool/Finucane/splicing_variation_in_humans_2022/data/01_data/new_results/all_EF_all_tissues_'+type_ss+'.csv.gz', \n",
    "                              compression = 'gzip',\n",
    "                              index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    top_EF_all_tissues.to_csv('/Users/hannahjacobs/Dropbox (MIT)/GradSchool/Finucane/splicing_variation_in_humans_2022/data/01_data/new_results/top_EF_all_tissues_'+type_ss+'.csv.gz', \n",
    "                              compression = 'gzip',\n",
    "                              index=True)\n",
    "\n",
    "    return all_EFs_above_5_percent_PSI, top_EF_all_tissues\n",
    "\n",
    "        \n",
    "   \n",
    "        \n",
    "                            \n",
    "    \n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1e90633-3672-4dd2-8b42-4c3a812ef578",
   "metadata": {},
   "outputs": [],
   "source": [
    "[all_EFs_above_5_percent_PSI_se, top_EF_all_tissues_se]= filter_and_save_exons_new('se')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b34b5091-3dc7-42ae-8eb6-6a69cc49da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intron_1=all_EFs_above_5_percent_PSI_alt_ss.intron_1.apply(lambda x: x.split(':clu')[0])\n",
    "\n",
    "intron_2=all_EFs_above_5_percent_PSI_alt_ss.intron_2.apply(lambda x: x.split(':clu')[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47580d-9007-4c6f-9e5c-81d6d8ccb4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94e2baf5-ad21-4d0d-877f-10b8fad56d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "[all_EFs_above_5_percent_PSI_alt_ss, top_EF_all_tissues_alt_ss]= filter_and_save_exons_new('alt_ss')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bfe914-c74a-4bf0-aead-5344526a1044",
   "metadata": {},
   "source": [
    "sum stats\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c763c65-f64a-4329-8f77-6120dd9d0164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top EF SE# = 58579\n",
      "all EF SE# = 278601\n",
      "top EF altss# = 190746\n",
      "all EF altss# = 793676\n"
     ]
    }
   ],
   "source": [
    "print('top EF SE# = '+str(len(top_EF_all_tissues_se)))\n",
    "\n",
    "print('all EF SE# = '+str(len(all_EFs_above_5_percent_PSI_se)))\n",
    "\n",
    "print('top EF altss# = '+str(len(top_EF_all_tissues_alt_ss)))\n",
    "\n",
    "print('all EF altss# = '+str(len(all_EFs_above_5_percent_PSI_alt_ss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c227fe4-2f4a-46a4-9985-2fc3062391ab",
   "metadata": {},
   "source": [
    "export this filtered set by EF, to filter for protein coding and maxent and size of exon in second (02) notebook\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5427c-4b66-4867-b782-aee4d2b2c84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "664d4f6e-91ae-4a96-8728-1d2376e8bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory='/Users/hannahjacobs/Dropbox (MIT)/GradSchool/Finucane/splicing_variation_in_humans_2022/data/01_data/new_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff485bed-21c1-4966-98f1-8c8f249cd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_EF_all_tissues_se.to_csv(data_directory+'top_EF_all_tissues_se.csv.gz',\n",
    "                                             compression='gzip',\n",
    "                                             index=False)\n",
    "\n",
    "top_EF_all_tissues_alt_ss.to_csv(data_directory+'top_EF_all_tissues_alt_ss.csv.gz',\n",
    "                                             compression='gzip',\n",
    "                                             index=False)\n",
    "\n",
    "\n",
    "all_EFs_above_5_percent_PSI_se.to_csv(data_directory+'all_EF_all_tissues_se.csv.gz',\n",
    "                                             compression='gzip',\n",
    "                                             index=False)\n",
    "\n",
    "all_EFs_above_5_percent_PSI_alt_ss.to_csv(data_directory+'all_EF_all_tissues_alt_ss.csv.gz',\n",
    "                                             compression='gzip',\n",
    "                                             index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
